# DeepPore: Automated Detection and Analysis of Congnitive Sweat Pore Activation using Neural Networks on Thermal Imaging Video

## Projecet Motivation:
This project demonstrates the feasibility of monitoring sweat pore activation (SPA) through thermal imaging video and deep neural networks as a measure of human performance during breathing and physical tasks. Our investigation addresses three key questions: 
1. Can deep learning models accurately detect sweat pore activation in thermal imaging while minimizing false positive? 
2. Does sweat pore activation correlate with breathing and physical movement? Our assumption is that sweat pore activity would increase with both types of effort and that this change will ouccr rapidly. 


## Features 
- Automated detection of sweat pores in thermal imaging videos
- Real-time visulization of pore activation patterns
- Temporal distribution analysis of activated pore counts
- Three CNN architectures with increasing complexity (LightNet, QuadCNN, DeepPoreNet)

## Design 
![Alt text](./docs/readme_imgs/dataset_generation.png)

Our ML pipeline transforms IR video into sweat pore detections in 7 steps:

1. Data collection: Gathered IR videos from University of Arizona Health Department
2. Frame extraction: Used FFmpeg to extract 1 frame per second
3. Patch generation: Split frames into 32×32 pixel patches
4. Ground truth creation: Calculated centroid coordinates with OpenCV
5. Model training: Built DeepPoreNet CNN for binary classification of patches
6. Application: Applied DeepPoreNet to detect activated sweat pores in each frame and put on a highlighted mask
7. Video creation: Combined sequence of highlighted frames into video using FFmpeg

## Dataset 
![Alt text](./docs/readme_imgs/dataset.png)


## Model Archetectures
DeepPoreNet, our best-performing model, implements a four-layer CNN with:
- Growing channel depths (1→16→32→64→128)
- 2×2 kernels with batch normalization
- ReLU activation
- Max-pooling after each convolutional block
- Five fully connected layers (128→64→32→16→8→2)
![Alt text](./docs/readme_imgs/deepPoreNet.png)

DeepPoreNet achieved:
- True Positive Rate (TPR): 72.3%
- True Negative Rate (TNR): 89.1%
- False Positive Rate (FPR): 10.9%
- False Negative Rate (FNR): 27.7%
- Accuracy: 86.7%

## Results
![Alt text](./docs/readme_imgs/temperal_distribution.png)
[![Video Title](https://img.youtube.com/vi/jkqaD_VT8t8/maxresdefault.jpg)](https://www.youtube.com/watch?v=jkqaD_VT8t8)
